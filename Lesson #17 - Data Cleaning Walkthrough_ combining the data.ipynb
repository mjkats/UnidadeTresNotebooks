{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lesson #17 - Data Cleaning Walkthrough_ combining the data.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Oi0OXsx48yFX","colab_type":"text"},"cell_type":"markdown","source":["# 1.0 Data Cleaning Walkthrough: Combining the Data"]},{"metadata":{"id":"93ZB_JG74yTT","colab_type":"code","colab":{}},"cell_type":"code","source":["import dill\n","dill.load_session('lesson_16.db')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H2CF1nWo8yFZ","colab_type":"text"},"cell_type":"markdown","source":["## 1.1 Introduction"]},{"metadata":{"id":"Z2x3NcmX8yFa","colab_type":"text"},"cell_type":"markdown","source":["In the last mission, we began investigating possible relationships between **SAT scores** and **demographic factors**. In order to do this, we acquired several data sets about [New York City public schools](https://data.cityofnewyork.us/data?cat=education). We manipulated these data sets, and found that we could combine them all using the **DBN** column. All of the data sets are currently stored as **keys** in the **data** dictionary. Each individual data set is a pandas dataframe.\n","\n","In this section, **we'll clean the data a bit more**, then **combine** it. Finally, we'll **compute correlations** and perform some analysis.\n","\n","The first thing we'll need to do in preparation for the merge is condense some of the data sets. In the last section, we noticed that the values in the **DBN** column were unique in the **sat_results** data set. Other data sets like **class_size** had duplicate **DBN** values, however.\n","\n","We'll need to condense these data sets so that each value in the **DBN** column is unique. If not, we'll run into issues when it comes time to combine the data sets.\n","\n","While the main data set we want to analyze, **sat_results**, has unique **DBN** values for every high school in New York City, other data sets aren't as clean. A single row in the **sat_results** data set may match multiple rows in the **class_size** data set, for example. This situation will create problems, because we don't know which of the multiple entries in the **class_size** data set we should combine with the single matching entry in **sat_results**. Here's a diagram that illustrates the problem:\n","\n","\n","<left><img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1deYm5RdQXO2xMX6dUgHLvqDEWipk3axq\"></left>\n","\n","In the diagram above, we can't just combine the rows from both data sets because there are several cases where multiple rows in **class_size** match a single row in **sat_results.**\n","\n","To resolve this issue, we'll condense the **class_size**, **graduation**, and **demographics** data sets so that each **DBN** is unique."]},{"metadata":{"id":"L46dQU968yFb","colab_type":"text"},"cell_type":"markdown","source":["## 1.2 Condensing the Class Size Data Set"]},{"metadata":{"id":"yRCu0U0-8yFc","colab_type":"text"},"cell_type":"markdown","source":["The first data set that we'll condense is **class_size**. The first few rows of **class_size** look like this:\n","\n","|__| CSD | BOROUGH | SCHOOL CODE | SCHOOL NAME               | GRADE | PROGRAM TYPE | CORE SUBJECT (MS CORE and 9-12 ONLY) | CORE COURSE (MS CORE and 9-12 ONLY) | SERVICE CATEGORY(K-9* ONLY) | NUMBER OF STUDENTS / SEATS FILLED | NUMBER OF SECTIONS |\n","|---|-----|---------|-------------|---------------------------|-------|--------------|--------------------------------------|-------------------------------------|-----------------------------|-----------------------------------|--------------------|\n","| 0 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | GEN ED       | -                                    | -                                   | -                           | 19.0                              | 1.0                |\n","| 1 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 0K    | CTT          | -                                    | -                                   | -                           | 21.0                              | 1.0                |\n","| 2 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | GEN ED       | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 3 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 01    | CTT          | -                                    | -                                   | -                           | 17.0                              | 1.0                |\n","| 4 | 1   | M       | M015        | P.S. 015 Roberto Clemente | 02    | GEN ED       | -                                    | -                                   | -                           | 15.0                              | 1.0                |\n","\n","As you can see, the first few rows all pertain to the same school, which is why the **DBN** appears more than once. It looks like each school has multiple values for **GRADE**, **PROGRAM TYPE**, **CORE SUBJECT (MS CORE and 9-12 ONLY)**, and **CORE COURSE (MS CORE and 9-12 ONLY)**.\n","\n","If we look at the unique values for **GRADE**, we get the following:\n","\n","```python\n","array(['0K', '01', '02', '03', '04', '05', '0K-09', nan, '06', '07', '08',\n","       'MS Core', '09-12', '09'], dtype=object)\n","```\n","\n","Because we're dealing with high schools, we're only concerned with grades 9 through 12. That means we only want to pick rows where the value in the **GRADE** column is **09-12**.\n","\n","If we look at the unique values for **PROGRAM TYPE**, we get the following:\n","\n","```python\n","array(['GEN ED', 'CTT', 'SPEC ED', nan, 'G&T'], dtype=object)\n","```\n","\n","Each school can have multiple program types. Because **GEN ED** is the largest category by far, let's only select rows where **PROGRAM TYPE** is **GEN ED**.\n","\n"]},{"metadata":{"id":"gL1mmbAK8yFc","colab_type":"text"},"cell_type":"markdown","source":["## 1.3 Condensing the Class Size Data Set"]},{"metadata":{"id":"8Zqa50Z08yFd","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","\n","- Create a new variable called **class_size**, and assign the value of **data[\"class_size\"]** to it.\n","- Filter **class_size** so the **GRADE** column only contains the value **09-12.** Note that the name of the **GRADE** column has a space at the end; you'll generate an error if you don't include it.\n","- Filter **lass_size** so that the **PROGRAM TYPE** column only contains the value **GEN ED.**\n","- Display the first five rows of **class_size** to verify."]},{"metadata":{"id":"8S8Ho7Tz8yFd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"a707b55c-0522-4b52-9026-18d76553fe0f","executionInfo":{"status":"ok","timestamp":1544460298730,"user_tz":180,"elapsed":1289,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["class_size = data['class_size']\n","class_size = class_size.loc[class_size['GRADE '] == '09-12']\n","class_size = class_size.loc[class_size['PROGRAM TYPE'] == 'GEN ED']\n","class_size.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CSD</th>\n","      <th>BOROUGH</th>\n","      <th>SCHOOL CODE</th>\n","      <th>SCHOOL NAME</th>\n","      <th>GRADE</th>\n","      <th>PROGRAM TYPE</th>\n","      <th>CORE SUBJECT (MS CORE and 9-12 ONLY)</th>\n","      <th>CORE COURSE (MS CORE and 9-12 ONLY)</th>\n","      <th>SERVICE CATEGORY(K-9* ONLY)</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>DATA SOURCE</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","      <th>padded_csd</th>\n","      <th>DBN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>225</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 9</td>\n","      <td>-</td>\n","      <td>63.0</td>\n","      <td>3.0</td>\n","      <td>21.0</td>\n","      <td>19.0</td>\n","      <td>25.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>226</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 10</td>\n","      <td>-</td>\n","      <td>79.0</td>\n","      <td>3.0</td>\n","      <td>26.3</td>\n","      <td>24.0</td>\n","      <td>31.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>227</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 11</td>\n","      <td>-</td>\n","      <td>38.0</td>\n","      <td>2.0</td>\n","      <td>19.0</td>\n","      <td>16.0</td>\n","      <td>22.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>228</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>ENGLISH</td>\n","      <td>English 12</td>\n","      <td>-</td>\n","      <td>69.0</td>\n","      <td>3.0</td>\n","      <td>23.0</td>\n","      <td>13.0</td>\n","      <td>30.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","    <tr>\n","      <th>229</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>M292</td>\n","      <td>Henry Street School for International Studies</td>\n","      <td>09-12</td>\n","      <td>GEN ED</td>\n","      <td>MATH</td>\n","      <td>Integrated Algebra</td>\n","      <td>-</td>\n","      <td>53.0</td>\n","      <td>3.0</td>\n","      <td>17.7</td>\n","      <td>16.0</td>\n","      <td>21.0</td>\n","      <td>STARS</td>\n","      <td>NaN</td>\n","      <td>01</td>\n","      <td>01M292</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     CSD BOROUGH SCHOOL CODE                                    SCHOOL NAME  \\\n","225    1       M        M292  Henry Street School for International Studies   \n","226    1       M        M292  Henry Street School for International Studies   \n","227    1       M        M292  Henry Street School for International Studies   \n","228    1       M        M292  Henry Street School for International Studies   \n","229    1       M        M292  Henry Street School for International Studies   \n","\n","    GRADE  PROGRAM TYPE CORE SUBJECT (MS CORE and 9-12 ONLY)  \\\n","225  09-12       GEN ED                              ENGLISH   \n","226  09-12       GEN ED                              ENGLISH   \n","227  09-12       GEN ED                              ENGLISH   \n","228  09-12       GEN ED                              ENGLISH   \n","229  09-12       GEN ED                                 MATH   \n","\n","    CORE COURSE (MS CORE and 9-12 ONLY) SERVICE CATEGORY(K-9* ONLY)  \\\n","225                           English 9                           -   \n","226                          English 10                           -   \n","227                          English 11                           -   \n","228                          English 12                           -   \n","229                  Integrated Algebra                           -   \n","\n","     NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n","225                               63.0                 3.0   \n","226                               79.0                 3.0   \n","227                               38.0                 2.0   \n","228                               69.0                 3.0   \n","229                               53.0                 3.0   \n","\n","     AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n","225                21.0                    19.0                   25.0   \n","226                26.3                    24.0                   31.0   \n","227                19.0                    16.0                   22.0   \n","228                23.0                    13.0                   30.0   \n","229                17.7                    16.0                   21.0   \n","\n","    DATA SOURCE  SCHOOLWIDE PUPIL-TEACHER RATIO padded_csd     DBN  \n","225       STARS                             NaN         01  01M292  \n","226       STARS                             NaN         01  01M292  \n","227       STARS                             NaN         01  01M292  \n","228       STARS                             NaN         01  01M292  \n","229       STARS                             NaN         01  01M292  "]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"Th72ZVIj8yFf","colab_type":"text"},"cell_type":"markdown","source":["## 1.4 Computing Average Class Sizes"]},{"metadata":{"id":"00ydSvyt8yFg","colab_type":"text"},"cell_type":"markdown","source":["As we saw when we displayed **class_size** on the last screen, **DBN** still isn't completely unique. This is due to the **CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** columns.\n","\n","**CORE COURSE (MS CORE and 9-12 ONLY)** and **CORE SUBJECT (MS CORE and 9-12 ONLY)** seem to pertain to different kinds of classes. For example, here are the unique values for **CORE SUBJECT (MS CORE and 9-12 ONLY)**:\n","\n","```python\n","array(['ENGLISH', 'MATH', 'SCIENCE', 'SOCIAL STUDIES'], dtype=object)\n","```\n","\n","This column only seems to include certain subjects. We want our class size data to include every single class a school offers -- not just a subset of them. What we can do is take the average across all of the classes a school offers. This will give us unique **DBN** values, while also incorporating as much data as possible into the average.\n","\n","Fortunately, we can use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to help us with this. The **DataFrame.groupby()** method will split a dataframe up into unique groups, based on a given column. We can then use the **agg()** method on the resulting **pandas.core.groupby** object to find the **mean** of each column.\n","\n","Let's say we have this data set:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1sJjENlTRR56RwYzBmmsU8aIMELgjx8zg\"></left>\n","\n","Using the **groupby()** method, we'll split this dataframe into four separate groups -- one with the **DBN 01M292**, one with the **DBN 01M332**, one with the **DBN 01M378**, and one with the **DBN 01M448**:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1y9imbMLKRDI50wQqPn7P6TAd6MfCL4Nq\"></left>\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1FitnyClxHDQLnoAB3jR7YI_jEPZZhkco\"></left>\n","\n","Then, we can compute the averages for the **AVERAGE CLASS SIZE** column in each of the four groups using the **agg()** method:\n","\n","<left><img width=\"200\" src=\"https://drive.google.com/uc?export=view&id=1gHVZixGOuGYYON_zU0OUPTJcC9Q_mKeV\"></left>\n","\n","After we group a dataframe and aggregate data based on it, the column we performed the grouping on (in this case **DBN**) will become the index, and will no longer appear as a column in the data itself. To undo this change and keep **DBN** as a column, we'll need to use [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html). This method will reset the index to a list of integers and make **DBN** a column again."]},{"metadata":{"id":"mMPOOzjN8yFg","colab_type":"text"},"cell_type":"markdown","source":["## 1.5 Computing Average Class Sizes"]},{"metadata":{"id":"sfdxxqf08yFh","colab_type":"text"},"cell_type":"markdown","source":["- Find the average values for each column associated with each **DBN** in **class_size**.\n","    - Use the [pandas.DataFrame.groupby()](http://pandas.pydata.org/pandas-docs/stable/groupby.html) method to group **class_size** by **DBN**.\n","    - Use the [agg()](http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation) method on the resulting **pandas.core.groupby** object, along with the **numpy.mean()** function as an argument, to calculate the average of each group.\n","    - Assign the result back to **class_size**.\n","- Reset the index to make **DBN** a column again.\n","    - Use the [pandas.DataFrame.reset_index()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html) method, along with the keyword argument **inplace=True**.\n","- Assign **class_size** back to the **class_size** key of the **data** dictionary.\n","- Display the first few rows of **data[\"class_size\"]** to verify that everything went okay."]},{"metadata":{"id":"xGKLTHOi8yFi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"1e5e6578-7130-449b-e253-bc779bb180b9","executionInfo":{"status":"ok","timestamp":1544460420272,"user_tz":180,"elapsed":1208,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","grouped_class = class_size.groupby('DBN')\n","grouped_class = grouped_class.aggregate(np.mean)\n","class_size = grouped_class\n","\n","class_size.reset_index(inplace=True)\n","data['class_size'] = class_size\n","\n","data['class_size'].head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>CSD</th>\n","      <th>NUMBER OF STUDENTS / SEATS FILLED</th>\n","      <th>NUMBER OF SECTIONS</th>\n","      <th>AVERAGE CLASS SIZE</th>\n","      <th>SIZE OF SMALLEST CLASS</th>\n","      <th>SIZE OF LARGEST CLASS</th>\n","      <th>SCHOOLWIDE PUPIL-TEACHER RATIO</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>01M292</td>\n","      <td>1</td>\n","      <td>88.0000</td>\n","      <td>4.000000</td>\n","      <td>22.564286</td>\n","      <td>18.50</td>\n","      <td>26.571429</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>01M332</td>\n","      <td>1</td>\n","      <td>46.0000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>21.00</td>\n","      <td>23.500000</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>01M378</td>\n","      <td>1</td>\n","      <td>33.0000</td>\n","      <td>1.000000</td>\n","      <td>33.000000</td>\n","      <td>33.00</td>\n","      <td>33.000000</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01M448</td>\n","      <td>1</td>\n","      <td>105.6875</td>\n","      <td>4.750000</td>\n","      <td>22.231250</td>\n","      <td>18.25</td>\n","      <td>27.062500</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01M450</td>\n","      <td>1</td>\n","      <td>57.6000</td>\n","      <td>2.733333</td>\n","      <td>21.200000</td>\n","      <td>19.40</td>\n","      <td>22.866667</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      DBN  CSD  NUMBER OF STUDENTS / SEATS FILLED  NUMBER OF SECTIONS  \\\n","0  01M292    1                            88.0000            4.000000   \n","1  01M332    1                            46.0000            2.000000   \n","2  01M378    1                            33.0000            1.000000   \n","3  01M448    1                           105.6875            4.750000   \n","4  01M450    1                            57.6000            2.733333   \n","\n","   AVERAGE CLASS SIZE  SIZE OF SMALLEST CLASS  SIZE OF LARGEST CLASS  \\\n","0           22.564286                   18.50              26.571429   \n","1           22.000000                   21.00              23.500000   \n","2           33.000000                   33.00              33.000000   \n","3           22.231250                   18.25              27.062500   \n","4           21.200000                   19.40              22.866667   \n","\n","   SCHOOLWIDE PUPIL-TEACHER RATIO  \n","0                             NaN  \n","1                             NaN  \n","2                             NaN  \n","3                             NaN  \n","4                             NaN  "]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"W4XtGPNh8yFl","colab_type":"text"},"cell_type":"markdown","source":["## 1.6 Condensing the Demographics Data Set"]},{"metadata":{"id":"ijDhJZeb8yFl","colab_type":"text"},"cell_type":"markdown","source":["Now that we've finished condensing **class_size**, let's condense **demographics**. The first few rows look like this:\n","\n","| _| DBN    | Name                      | schoolyear | fl_percent | frl_percent | total_enrollment | prek | k  | grade1 | grade2 |\n","|---|--------|---------------------------|------------|------------|-------------|------------------|------|----|--------|--------|\n","| 0 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20052006   | 89.4       | NaN         | 281              | 15   | 36 | 40     | 33     |\n","| 1 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20062007   | 89.4       | NaN         | 243              | 15   | 29 | 39     | 38     |\n","| 2 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20072008   | 89.4       | NaN         | 261              | 18   | 43 | 39     | 36     |\n","| 3 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20082009   | 89.4       | NaN         | 252              | 17   | 37 | 44     | 32     |\n","| 4 | 01M015 | P.S. 015 ROBERTO CLEMENTE | 20092010   |  _          | 96.5        | 208              | 16   | 40 | 28     | 32     |\n","\n","In this case, the only column that prevents a given **DBN** from being unique is **schoolyear**. We only want to select rows where schoolyear is **20112012**. This will give us the most recent year of data, and also match our SAT results data."]},{"metadata":{"id":"VnDEAeuB8yFn","colab_type":"text"},"cell_type":"markdown","source":["## 1.7 Condensing the Demographics Data Set"]},{"metadata":{"id":"C5g2PiJt8yFn","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **demographics**, only selecting rows in **data[\"demographics\"]** where **schoolyear** is **20112012.**\n","    - **schoolyear** is actually an integer, so be careful about how you perform your comparison.\n","- Display the first few rows of **data[\"demographics\"]** to verify that the filtering worked."]},{"metadata":{"id":"4QUcmKI28yFo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":440},"outputId":"16090c9f-2aaa-423d-c720-642dd771999a","executionInfo":{"status":"ok","timestamp":1544460320493,"user_tz":180,"elapsed":8903,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["data['demographics'] = data['demographics'].loc[data['demographics']['schoolyear'] == 20112012]\n","\n","data['demographics'].head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DBN</th>\n","      <th>Name</th>\n","      <th>schoolyear</th>\n","      <th>fl_percent</th>\n","      <th>frl_percent</th>\n","      <th>total_enrollment</th>\n","      <th>prek</th>\n","      <th>k</th>\n","      <th>grade1</th>\n","      <th>grade2</th>\n","      <th>...</th>\n","      <th>black_num</th>\n","      <th>black_per</th>\n","      <th>hispanic_num</th>\n","      <th>hispanic_per</th>\n","      <th>white_num</th>\n","      <th>white_per</th>\n","      <th>male_num</th>\n","      <th>male_per</th>\n","      <th>female_num</th>\n","      <th>female_per</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>01M015</td>\n","      <td>P.S. 015 ROBERTO CLEMENTE</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>89.4</td>\n","      <td>189</td>\n","      <td>13</td>\n","      <td>31</td>\n","      <td>35</td>\n","      <td>28</td>\n","      <td>...</td>\n","      <td>63</td>\n","      <td>33.3</td>\n","      <td>109</td>\n","      <td>57.7</td>\n","      <td>4</td>\n","      <td>2.1</td>\n","      <td>97.0</td>\n","      <td>51.3</td>\n","      <td>92.0</td>\n","      <td>48.7</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>01M019</td>\n","      <td>P.S. 019 ASHER LEVY</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>61.5</td>\n","      <td>328</td>\n","      <td>32</td>\n","      <td>46</td>\n","      <td>52</td>\n","      <td>54</td>\n","      <td>...</td>\n","      <td>81</td>\n","      <td>24.7</td>\n","      <td>158</td>\n","      <td>48.2</td>\n","      <td>28</td>\n","      <td>8.5</td>\n","      <td>147.0</td>\n","      <td>44.8</td>\n","      <td>181.0</td>\n","      <td>55.2</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>01M020</td>\n","      <td>PS 020 ANNA SILVER</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>92.5</td>\n","      <td>626</td>\n","      <td>52</td>\n","      <td>102</td>\n","      <td>121</td>\n","      <td>87</td>\n","      <td>...</td>\n","      <td>55</td>\n","      <td>8.8</td>\n","      <td>357</td>\n","      <td>57.0</td>\n","      <td>16</td>\n","      <td>2.6</td>\n","      <td>330.0</td>\n","      <td>52.7</td>\n","      <td>296.0</td>\n","      <td>47.3</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>01M034</td>\n","      <td>PS 034 FRANKLIN D ROOSEVELT</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>99.7</td>\n","      <td>401</td>\n","      <td>14</td>\n","      <td>34</td>\n","      <td>38</td>\n","      <td>36</td>\n","      <td>...</td>\n","      <td>90</td>\n","      <td>22.4</td>\n","      <td>275</td>\n","      <td>68.6</td>\n","      <td>8</td>\n","      <td>2.0</td>\n","      <td>204.0</td>\n","      <td>50.9</td>\n","      <td>197.0</td>\n","      <td>49.1</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>01M063</td>\n","      <td>PS 063 WILLIAM MCKINLEY</td>\n","      <td>20112012</td>\n","      <td>NaN</td>\n","      <td>78.9</td>\n","      <td>176</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>30</td>\n","      <td>21</td>\n","      <td>...</td>\n","      <td>41</td>\n","      <td>23.3</td>\n","      <td>110</td>\n","      <td>62.5</td>\n","      <td>15</td>\n","      <td>8.5</td>\n","      <td>97.0</td>\n","      <td>55.1</td>\n","      <td>79.0</td>\n","      <td>44.9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 38 columns</p>\n","</div>"],"text/plain":["       DBN                                              Name  schoolyear  \\\n","6   01M015  P.S. 015 ROBERTO CLEMENTE                           20112012   \n","13  01M019  P.S. 019 ASHER LEVY                                 20112012   \n","20  01M020  PS 020 ANNA SILVER                                  20112012   \n","27  01M034  PS 034 FRANKLIN D ROOSEVELT                         20112012   \n","35  01M063  PS 063 WILLIAM MCKINLEY                             20112012   \n","\n","   fl_percent  frl_percent  total_enrollment prek    k grade1 grade2  \\\n","6         NaN         89.4               189   13   31     35     28   \n","13        NaN         61.5               328   32   46     52     54   \n","20        NaN         92.5               626   52  102    121     87   \n","27        NaN         99.7               401   14   34     38     36   \n","35        NaN         78.9               176   18   20     30     21   \n","\n","      ...     black_num black_per hispanic_num hispanic_per white_num  \\\n","6     ...            63      33.3          109         57.7         4   \n","13    ...            81      24.7          158         48.2        28   \n","20    ...            55       8.8          357         57.0        16   \n","27    ...            90      22.4          275         68.6         8   \n","35    ...            41      23.3          110         62.5        15   \n","\n","   white_per male_num male_per female_num female_per  \n","6        2.1     97.0     51.3       92.0       48.7  \n","13       8.5    147.0     44.8      181.0       55.2  \n","20       2.6    330.0     52.7      296.0       47.3  \n","27       2.0    204.0     50.9      197.0       49.1  \n","35       8.5     97.0     55.1       79.0       44.9  \n","\n","[5 rows x 38 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"x5dkSi8s8yFs","colab_type":"text"},"cell_type":"markdown","source":["## 1.8 Condensing the Graduation Data Set"]},{"metadata":{"id":"5xQzgi_Q8yFs","colab_type":"text"},"cell_type":"markdown","source":["Finally, we'll need to condense the **graduation** data set. Here are the first few rows:\n","\n","| _ | Demographic  | DBN    | School Name                           | Cohort   | Total Cohort | Total Grads - n |\n","|---|--------------|--------|---------------------------------------|----------|--------------|-----------------|\n","| 0 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2003     | 5            | s               |\n","| 1 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2004     | 55           | 37              |\n","| 2 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2005     | 64           | 43              |\n","| 3 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006     | 78           | 43              |\n","| 4 | Total Cohort | 01M292 | HENRY STREET SCHOOL FOR INTERNATIONAL | 2006 Aug | 78           | 44              |\n","\n","The **Demographic** and **Cohort** columns are what prevent **DBN** from being unique in the **graduation** data. A **Cohort** appears to refer to the year the data represents, and the **Demographic** appears to refer to a specific demographic group. In this case, we want to pick data from the most recent Cohort available, which is 2006. We also want data from the full cohort, so we'll only pick rows where **Demographic** is **Total Cohort**."]},{"metadata":{"id":"IIHasD3G8yFt","colab_type":"text"},"cell_type":"markdown","source":["## 1.9 Condensing the Graduation Data Set"]},{"metadata":{"id":"7m8fZlxr8yFv","colab_type":"text"},"cell_type":"markdown","source":["**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Filter **graduation**, only selecting rows where the **Cohort** column equals **2006.**\n","- Filter **graduation**, only selecting rows where the **Demographic** column equals **Total Cohort**.\n","- Display the first few rows of **data[\"graduation\"]** to verify that everything worked properly."]},{"metadata":{"id":"JjMUikQu8yFv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":491},"outputId":"46b2204c-7605-47df-fe59-f16ec4e2e1ec","executionInfo":{"status":"ok","timestamp":1544460325830,"user_tz":180,"elapsed":862,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["data['graduation'] = data['graduation'].loc[data['graduation']['Cohort'] == '2006']\n","data['graduation'] = data['graduation'].loc[data['graduation']['Demographic'] == 'Total Cohort']\n","\n","data['graduation'].head()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Demographic</th>\n","      <th>DBN</th>\n","      <th>School Name</th>\n","      <th>Cohort</th>\n","      <th>Total Cohort</th>\n","      <th>Total Grads - n</th>\n","      <th>Total Grads - % of cohort</th>\n","      <th>Total Regents - n</th>\n","      <th>Total Regents - % of cohort</th>\n","      <th>Total Regents - % of grads</th>\n","      <th>...</th>\n","      <th>Regents w/o Advanced - n</th>\n","      <th>Regents w/o Advanced - % of cohort</th>\n","      <th>Regents w/o Advanced - % of grads</th>\n","      <th>Local - n</th>\n","      <th>Local - % of cohort</th>\n","      <th>Local - % of grads</th>\n","      <th>Still Enrolled - n</th>\n","      <th>Still Enrolled - % of cohort</th>\n","      <th>Dropped Out - n</th>\n","      <th>Dropped Out - % of cohort</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>Total Cohort</td>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL</td>\n","      <td>2006</td>\n","      <td>78</td>\n","      <td>43</td>\n","      <td>55.1</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>83.7</td>\n","      <td>...</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>83.7</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>16.3</td>\n","      <td>16</td>\n","      <td>20.5</td>\n","      <td>11</td>\n","      <td>14.1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Total Cohort</td>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>124</td>\n","      <td>53</td>\n","      <td>42.7</td>\n","      <td>42</td>\n","      <td>33.9</td>\n","      <td>79.2</td>\n","      <td>...</td>\n","      <td>34</td>\n","      <td>27.4</td>\n","      <td>64.2</td>\n","      <td>11</td>\n","      <td>8.9</td>\n","      <td>20.8</td>\n","      <td>46</td>\n","      <td>37.1</td>\n","      <td>20</td>\n","      <td>16.100000000000001</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Total Cohort</td>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>2006</td>\n","      <td>90</td>\n","      <td>70</td>\n","      <td>77.8</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>95.7</td>\n","      <td>...</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>95.7</td>\n","      <td>3</td>\n","      <td>3.3</td>\n","      <td>4.3</td>\n","      <td>15</td>\n","      <td>16.7</td>\n","      <td>5</td>\n","      <td>5.6</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Total Cohort</td>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>56</td>\n","      <td>40</td>\n","      <td>47.6</td>\n","      <td>85.1</td>\n","      <td>...</td>\n","      <td>23</td>\n","      <td>27.4</td>\n","      <td>48.9</td>\n","      <td>7</td>\n","      <td>8.300000000000001</td>\n","      <td>14.9</td>\n","      <td>25</td>\n","      <td>29.8</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Total Cohort</td>\n","      <td>01M515</td>\n","      <td>LOWER EAST SIDE PREPARATORY HIGH SCHO</td>\n","      <td>2006</td>\n","      <td>193</td>\n","      <td>105</td>\n","      <td>54.4</td>\n","      <td>91</td>\n","      <td>47.2</td>\n","      <td>86.7</td>\n","      <td>...</td>\n","      <td>22</td>\n","      <td>11.4</td>\n","      <td>21</td>\n","      <td>14</td>\n","      <td>7.3</td>\n","      <td>13.3</td>\n","      <td>53</td>\n","      <td>27.5</td>\n","      <td>35</td>\n","      <td>18.100000000000001</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["     Demographic     DBN                            School Name Cohort  \\\n","3   Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL   2006   \n","10  Total Cohort  01M448    UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   2006   \n","17  Total Cohort  01M450             EAST SIDE COMMUNITY SCHOOL   2006   \n","24  Total Cohort  01M509                MARTA VALLE HIGH SCHOOL   2006   \n","31  Total Cohort  01M515  LOWER EAST SIDE PREPARATORY HIGH SCHO   2006   \n","\n","    Total Cohort Total Grads - n Total Grads - % of cohort Total Regents - n  \\\n","3             78              43                      55.1                36   \n","10           124              53                      42.7                42   \n","17            90              70                      77.8                67   \n","24            84              47                        56                40   \n","31           193             105                      54.4                91   \n","\n","   Total Regents - % of cohort Total Regents - % of grads  \\\n","3                         46.2                       83.7   \n","10                        33.9                       79.2   \n","17          74.400000000000006                       95.7   \n","24                        47.6                       85.1   \n","31                        47.2                       86.7   \n","\n","              ...            Regents w/o Advanced - n  \\\n","3             ...                                  36   \n","10            ...                                  34   \n","17            ...                                  67   \n","24            ...                                  23   \n","31            ...                                  22   \n","\n","   Regents w/o Advanced - % of cohort Regents w/o Advanced - % of grads  \\\n","3                                46.2                              83.7   \n","10                               27.4                              64.2   \n","17                 74.400000000000006                              95.7   \n","24                               27.4                              48.9   \n","31                               11.4                                21   \n","\n","   Local - n Local - % of cohort Local - % of grads Still Enrolled - n  \\\n","3          7                   9               16.3                 16   \n","10        11                 8.9               20.8                 46   \n","17         3                 3.3                4.3                 15   \n","24         7   8.300000000000001               14.9                 25   \n","31        14                 7.3               13.3                 53   \n","\n","   Still Enrolled - % of cohort Dropped Out - n Dropped Out - % of cohort  \n","3                          20.5              11                      14.1  \n","10                         37.1              20        16.100000000000001  \n","17                         16.7               5                       5.6  \n","24                         29.8               5                         6  \n","31                         27.5              35        18.100000000000001  \n","\n","[5 rows x 23 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"ak0EfoSm8yFy","colab_type":"text"},"cell_type":"markdown","source":["## 1.10 Converting AP Test Scores"]},{"metadata":{"id":"DMmk__7t8yFy","colab_type":"text"},"cell_type":"markdown","source":["We're almost ready to combine all of the data sets. The only remaining thing to do is convert the [Advanced Placement (AP)](https://en.wikipedia.org/wiki/Advanced_Placement_exams) test scores from strings to numeric values. High school students take the AP exams before applying to college. There are several AP exams, each corresponding to a school subject. High school students who earn high scores may receive college credit.\n","\n","AP exams have a 1 to 5 scale; 3 or higher is a passing score. Many high school students take AP exams -- particularly those who attend academically challenging institutions. AP exams are much more rare in schools that lack funding or academic rigor.\n","\n","It will be interesting to find out whether AP exam scores are correlated with SAT scores across high schools. To determine this, we'll need to convert the AP exam scores in the **ap_2010** data set to numeric values first.\n","\n","There are three columns we'll need to convert:\n","\n","- **AP Test Takers** (note that there's a trailing space in the column name)\n","- **Total Exams Taken**\n","- **Number of Exams with scores 3 4 or 5**\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Convert each of the following columns in **ap_2010** to numeric values using the [pandas.to_numeric()](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.to_numeric.html) function with the keyword argument **errors=\"coerce\".**\n","    - **AP Test Takers**\n","    - **Total Exams Taken**\n","    - **Number of Exams with scores 3 4 or 5**\n","- Display the column types using the **dtypes** attribute."]},{"metadata":{"id":"_qW0QDiM8yFz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"8e64db36-9fd0-421f-ffba-81007e7e9167","executionInfo":{"status":"ok","timestamp":1544460335994,"user_tz":180,"elapsed":683,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["data['ap_2010']['AP Test Takers '] = pd.to_numeric(data['ap_2010']['AP Test Takers '], errors='coerce')\n","data['ap_2010']['Total Exams Taken'] = pd.to_numeric(data['ap_2010']['Total Exams Taken'], errors='coerce')\n","data['ap_2010']['Number of Exams with scores 3 4 or 5'] = pd.to_numeric(data['ap_2010']['Number of Exams with scores 3 4 or 5'], errors='coerce')\n","\n","print(data['ap_2010']['Number of Exams with scores 3 4 or 5'].dtype)\n","print(data['ap_2010']['Total Exams Taken'].dtype)\n","print(data['ap_2010']['AP Test Takers '].dtype)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["float64\n","float64\n","float64\n"],"name":"stdout"}]},{"metadata":{"id":"8sB0lAzH8yF0","colab_type":"text"},"cell_type":"markdown","source":["## 1.11 Left, Right, Inner, and Outer Joins"]},{"metadata":{"id":"Vjm8aBE68yF1","colab_type":"text"},"cell_type":"markdown","source":["Before we merge our data, we'll need to decide on the merge strategy we want to use. We'll be using the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) function, which supports four types of joins -- **left**, **right**, **inner**, and **outer**. Each of these join types dictates how pandas combines the rows.\n","\n","We'll be using the **DBN** column to identify matching rows across data sets. In other words, the values in that column will help us know which row from the first data set to combine with which row in the second data set.\n","\n","There may be **DBN** values that exist in one data set but not in another. This is partly because the data is from different years. Each data set also has inconsistencies in terms of how it was gathered. Human error (and other types of errors) may also play a role. Therefore, we may not find matches for the **DBN** values in **sat_results** in all of the other data sets, and other data sets may have **DBN** values that don't exist in **sat_results**.\n","\n","We'll merge two data sets at a time. For example, we'll merge **sat_results** and **hs_directory**, then merge the result with **ap_2010**, then merge the result of that with **class_size**. We'll continue combining data sets in this way until we've merged all of them. Afterwards, we'll have roughly the same number of rows, but each row will have columns from all of the data sets.\n","\n","The merge strategy we pick will affect the number of rows we end up with. Let's take a look at each strategy.\n","\n","Let's say we're merging the following two data sets:\n","\n","<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Vlypix_SIkxCdRS0ABvO4tGiuvFLg321\"></left>\n","\n","With an **inner merge**, we'd only combine rows where the same **DBN** exists in both data sets. We'd end up with this result:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1LR4c8louX-JAZFYta_Y99FLsGkCf9grr\"></left>\n","\n","With a **left merge**, we'd only use **DBN** values from the dataframe on the \"left\" of the merge. In this case, **sat_results** is on the left. Some of the DBNs in **sat_results** don't exist in **class_size**, though. The merge will handle this by assiging null values to the columns in **sat_results** that don't have corresponding data in **class_size.**\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1hPoJ5wLECEzz25jrTP5bw9oZ0eerNi2p\"></left>\n","\n","With a **right merge**, we'll only use **DBN** values from the dataframe on the \"right\" of the merge. In this case, **class_size** is on the right:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1YYdf4iEMtHYqRBMTEFcfuTyu9zdFlnx7\"></left>\n","\n","With an outer merge, we'll take any DBN values from either sat_results or class_size:\n","\n","<left><img width=\"600\" src=\"https://drive.google.com/uc?export=view&id=1sl5wCK3WZ3lTzJm8JUn-bg4MoXl3xSe9\"></left>\n","\n","As you can see, each merge strategy has its advantages. Depending on the strategy we choose, we may preserve rows at the expense of having more missing column data, or minimize missing data at the expense of having fewer rows. Choosing a merge strategy is an important decision; it's worth thinking about your data carefully, and what trade-offs you're willing to make.\n","\n","Because this project is concerned with determing demographic factors that correlate with SAT score, we'll want to preserve as many rows as possible from **sat_results** while minimizing null values.\n","\n","This means that we may need to use different merge strategies with different data sets. Some of the data sets have a lot of missing **DBN** values. This makes a **left** join more appropriate, because we don't want to lose too many rows when we merge. If we did an **inner** join, we would lose the data for many high schools.\n","\n","Some data sets have **DBN** values that are almost identical to those in **sat_results**. Those data sets also have information we need to keep. Most of our analysis would be impossible if a significant number of rows was missing from **demographics**, for example. Therefore, we'll do an inner join to avoid missing data in these columns."]},{"metadata":{"id":"XpPfMAwI8yF1","colab_type":"text"},"cell_type":"markdown","source":["##  1.12 Performing the Left Joins"]},{"metadata":{"id":"TC5oEhTL8yF2","colab_type":"text"},"cell_type":"markdown","source":["Both the **ap_2010** and the **graduation** data sets have many missing **DBN** values, so we'll use a left join when we merge the **sat_results** data set with them. Because we're using a **left** join, our final dataframe will have all of the same **DBN** values as the original **sat_results** dataframe.\n","\n","We'll need to use the pandas **df.merge()** method to merge dataframes. The \"left\" dataframe is the one we call the method on, and the \"right\" dataframe is the one we pass into **df.merge()**.\n","\n","Because we're using the **DBN** column to join the dataframes, we'll need to specify the keyword argument **on=\"DBN\"** when calling **pandas.DataFrame.merge().**\n","\n","First, we'll assign **data[\"sat_results\"]** to the variable **combined**. Then, we'll merge all of the other dataframes with **combined**. When we're finished, **combined** will have all of the columns from all of the data sets.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Use the pandas [pandas.DataFrame.merge()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) method to merge the **ap_2010** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to indicate the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Use the pandas **df.merge()** method to merge the **graduation** data set into **combined.**\n","    - Make sure to specify **how=\"left\"** as a keyword argument to get the correct join type.\n","    - Make sure to assign the result of the merge operation back to **combined.**\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Use the [pandas.DataFrame.shape](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.shape.html) attribute to display the shape of the dataframe and see how many rows now exist."]},{"metadata":{"id":"06arIDoX8yF3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":471},"outputId":"660343e6-9ef8-4a2c-ba52-7a609b992b5d","executionInfo":{"status":"ok","timestamp":1544460588179,"user_tz":180,"elapsed":889,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["combined = data['sat_results']\n","combined = pd.merge(data['ap_2010'], combined, how='left')\n","combined = pd.merge(data['graduation'], combined, how='left')\n","combined.head()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Demographic</th>\n","      <th>DBN</th>\n","      <th>School Name</th>\n","      <th>Cohort</th>\n","      <th>Total Cohort</th>\n","      <th>Total Grads - n</th>\n","      <th>Total Grads - % of cohort</th>\n","      <th>Total Regents - n</th>\n","      <th>Total Regents - % of cohort</th>\n","      <th>Total Regents - % of grads</th>\n","      <th>...</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>Number of Exams with scores 3 4 or 5</th>\n","      <th>SCHOOL NAME</th>\n","      <th>Num of SAT Test Takers</th>\n","      <th>SAT Critical Reading Avg. Score</th>\n","      <th>SAT Math Avg. Score</th>\n","      <th>SAT Writing Avg. Score</th>\n","      <th>sat_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Total Cohort</td>\n","      <td>01M292</td>\n","      <td>HENRY STREET SCHOOL FOR INTERNATIONAL</td>\n","      <td>2006</td>\n","      <td>78</td>\n","      <td>43</td>\n","      <td>55.1</td>\n","      <td>36</td>\n","      <td>46.2</td>\n","      <td>83.7</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Total Cohort</td>\n","      <td>01M448</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>124</td>\n","      <td>53</td>\n","      <td>42.7</td>\n","      <td>42</td>\n","      <td>33.9</td>\n","      <td>79.2</td>\n","      <td>...</td>\n","      <td>UNIVERSITY NEIGHBORHOOD H.S.</td>\n","      <td>39.0</td>\n","      <td>49.0</td>\n","      <td>10.0</td>\n","      <td>UNIVERSITY NEIGHBORHOOD HIGH SCHOOL</td>\n","      <td>91</td>\n","      <td>383.0</td>\n","      <td>423.0</td>\n","      <td>366.0</td>\n","      <td>1172.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Total Cohort</td>\n","      <td>01M450</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>2006</td>\n","      <td>90</td>\n","      <td>70</td>\n","      <td>77.8</td>\n","      <td>67</td>\n","      <td>74.400000000000006</td>\n","      <td>95.7</td>\n","      <td>...</td>\n","      <td>EAST SIDE COMMUNITY HS</td>\n","      <td>19.0</td>\n","      <td>21.0</td>\n","      <td>NaN</td>\n","      <td>EAST SIDE COMMUNITY SCHOOL</td>\n","      <td>70</td>\n","      <td>377.0</td>\n","      <td>402.0</td>\n","      <td>370.0</td>\n","      <td>1149.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Total Cohort</td>\n","      <td>01M509</td>\n","      <td>MARTA VALLE HIGH SCHOOL</td>\n","      <td>2006</td>\n","      <td>84</td>\n","      <td>47</td>\n","      <td>56</td>\n","      <td>40</td>\n","      <td>47.6</td>\n","      <td>85.1</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Total Cohort</td>\n","      <td>01M515</td>\n","      <td>LOWER EAST SIDE PREPARATORY HIGH SCHO</td>\n","      <td>2006</td>\n","      <td>193</td>\n","      <td>105</td>\n","      <td>54.4</td>\n","      <td>91</td>\n","      <td>47.2</td>\n","      <td>86.7</td>\n","      <td>...</td>\n","      <td>LOWER EASTSIDE PREP</td>\n","      <td>24.0</td>\n","      <td>26.0</td>\n","      <td>24.0</td>\n","      <td>LOWER EAST SIDE PREPARATORY HIGH SCHOOL</td>\n","      <td>112</td>\n","      <td>332.0</td>\n","      <td>557.0</td>\n","      <td>316.0</td>\n","      <td>1205.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 33 columns</p>\n","</div>"],"text/plain":["    Demographic     DBN                            School Name Cohort  \\\n","0  Total Cohort  01M292  HENRY STREET SCHOOL FOR INTERNATIONAL   2006   \n","1  Total Cohort  01M448    UNIVERSITY NEIGHBORHOOD HIGH SCHOOL   2006   \n","2  Total Cohort  01M450             EAST SIDE COMMUNITY SCHOOL   2006   \n","3  Total Cohort  01M509                MARTA VALLE HIGH SCHOOL   2006   \n","4  Total Cohort  01M515  LOWER EAST SIDE PREPARATORY HIGH SCHO   2006   \n","\n","   Total Cohort Total Grads - n Total Grads - % of cohort Total Regents - n  \\\n","0            78              43                      55.1                36   \n","1           124              53                      42.7                42   \n","2            90              70                      77.8                67   \n","3            84              47                        56                40   \n","4           193             105                      54.4                91   \n","\n","  Total Regents - % of cohort Total Regents - % of grads    ...     \\\n","0                        46.2                       83.7    ...      \n","1                        33.9                       79.2    ...      \n","2          74.400000000000006                       95.7    ...      \n","3                        47.6                       85.1    ...      \n","4                        47.2                       86.7    ...      \n","\n","                     SchoolName AP Test Takers  Total Exams Taken  \\\n","0                           NaN             NaN               NaN   \n","1  UNIVERSITY NEIGHBORHOOD H.S.            39.0              49.0   \n","2        EAST SIDE COMMUNITY HS            19.0              21.0   \n","3                           NaN             NaN               NaN   \n","4           LOWER EASTSIDE PREP            24.0              26.0   \n","\n","  Number of Exams with scores 3 4 or 5  \\\n","0                                  NaN   \n","1                                 10.0   \n","2                                  NaN   \n","3                                  NaN   \n","4                                 24.0   \n","\n","                               SCHOOL NAME Num of SAT Test Takers  \\\n","0                                      NaN                    NaN   \n","1      UNIVERSITY NEIGHBORHOOD HIGH SCHOOL                     91   \n","2               EAST SIDE COMMUNITY SCHOOL                     70   \n","3                                      NaN                    NaN   \n","4  LOWER EAST SIDE PREPARATORY HIGH SCHOOL                    112   \n","\n","  SAT Critical Reading Avg. Score SAT Math Avg. Score SAT Writing Avg. Score  \\\n","0                             NaN                 NaN                    NaN   \n","1                           383.0               423.0                  366.0   \n","2                           377.0               402.0                  370.0   \n","3                             NaN                 NaN                    NaN   \n","4                           332.0               557.0                  316.0   \n","\n","  sat_score  \n","0       NaN  \n","1    1172.0  \n","2    1149.0  \n","3       NaN  \n","4    1205.0  \n","\n","[5 rows x 33 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"metadata":{"id":"VMMJAmet8yF6","colab_type":"text"},"cell_type":"markdown","source":["## 1.13 Performing the Inner Joins"]},{"metadata":{"id":"Nn8-wD4k8yF7","colab_type":"text"},"cell_type":"markdown","source":["Now that we've performed the left joins, we still have to merge **class_size**, **demographics**, **survey**, and **hs_directory** into **combined**. Because these files contain information that's more valuable to our analysis and also have fewer missing **DBN** values, we'll use the **inner** join type.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Merge **class_size** into **combined**. Then, merge **demographics**, **survey**, and **hs_directory** into **combined** one by one, in that order.\n","    - Be sure to follow the exact order above.\n","    - Remember to specify the correct column to join on, as well as the correct join type.\n","- Display the first few rows of **combined** to verify that the correct operations occurred.\n","- Call **pandas.DataFrame.shape()** to display the shape of the dataframe to see how many rows now exist."]},{"metadata":{"id":"xEbfC4f58yF8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1061},"outputId":"9c516fc9-962f-49e0-a97f-a2a1f8c6565c","executionInfo":{"status":"ok","timestamp":1544460662996,"user_tz":180,"elapsed":632,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["combined = pd.merge(data['class_size'], combined, how='inner')\n","combined = pd.merge(data['demographics'], combined, how='inner')\n","combined = pd.merge(new_survey, combined, how='inner')\n","combined = pd.merge(data['hs_directory'], combined, how='inner')\n","\n","print(combined.head())\n","print(combined.shape)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["      dbn                                        school_name    borough  \\\n","0  17K548                Brooklyn School for Music & Theatre   Brooklyn   \n","1  09X543                   High School for Violin and Dance      Bronx   \n","2  28Q680  Queens Gateway to Health Sciences Secondary Sc...     Queens   \n","3  14K474      PROGRESS High School for Professional Careers   Brooklyn   \n","4  02M420  High School for Health Professions and Human S...  Manhattan   \n","\n","  building_code  phone_number    fax_number  grade_span_min  grade_span_max  \\\n","0          K440  718-230-6250  718-230-6262             9.0              12   \n","1          X400  718-842-0687  718-589-9849             9.0              12   \n","2          Q695  718-969-3155  718-969-3552             6.0              12   \n","3          K450  718-387-0228  718-782-0911             9.0              12   \n","4          M475  212-780-9175  212-979-7261             9.0              12   \n","\n","   expgrade_span_min  expgrade_span_max    ...     \\\n","0                NaN                NaN    ...      \n","1                NaN                NaN    ...      \n","2                NaN                NaN    ...      \n","3                NaN                NaN    ...      \n","4                NaN                NaN    ...      \n","\n","                            SchoolName AP Test Takers  Total Exams Taken  \\\n","0  Brooklyn School for Music & Theatre            37.0              41.0   \n","1                                  NaN             NaN               NaN   \n","2           GATEWAY TO HEALTH SCIENCES            89.0             136.0   \n","3                 PROGRESS HIGH SCHOOL            50.0              66.0   \n","4             HEALTH PROF & HUMAN SVCS           204.0             248.0   \n","\n","  Number of Exams with scores 3 4 or 5  \\\n","0                                  9.0   \n","1                                  NaN   \n","2                                 57.0   \n","3                                  NaN   \n","4                                 75.0   \n","\n","                                         SCHOOL NAME  Num of SAT Test Takers  \\\n","0                BROOKLYN SCHOOL FOR MUSIC & THEATRE                      48   \n","1                                                NaN                     NaN   \n","2  QUEENS GATEWAY TO HEALTH SCIENCES SECONDARY SC...                      99   \n","3      PROGRESS HIGH SCHOOL FOR PROFESSIONAL CAREERS                     144   \n","4  HIGH SCHOOL FOR HEALTH PROFESSIONS AND HUMAN S...                     336   \n","\n","  SAT Critical Reading Avg. Score  SAT Math Avg. Score SAT Writing Avg. Score  \\\n","0                           385.0                393.0                  373.0   \n","1                             NaN                  NaN                    NaN   \n","2                           513.0                523.0                  502.0   \n","3                           364.0                379.0                  371.0   \n","4                           429.0                449.0                  428.0   \n","\n","  sat_score  \n","0    1151.0  \n","1       NaN  \n","2    1538.0  \n","3    1114.0  \n","4    1306.0  \n","\n","[5 rows x 165 columns]\n","(310, 165)\n"],"name":"stdout"}]},{"metadata":{"id":"LoZeRh6W8yF_","colab_type":"text"},"cell_type":"markdown","source":["##  1.14 Filling in Missing Values"]},{"metadata":{"id":"G_P59inq8yF_","colab_type":"text"},"cell_type":"markdown","source":["You may have noticed that the inner joins resulted in 116 fewer rows in **sat_results**. This is because pandas couldn't find the **DBN** values that existed in **sat_results** in the other data sets. While this is worth investigating, we're currently looking for high-level correlations, so we don't need to dive into which **DBNs** are missing.\n","\n","You may also have noticed that we now have many columns with null (**NaN**) values. This is because we chose to do **left** joins, where some columns may not have had data. The data set also had some missing values to begin with. If we hadn't performed a **left** join, all of the rows with missing data would have been lost in the merge process, which wouldn't have left us with many high schools in our data set.\n","\n","There are several ways to handle missing data, and we'll cover them in more detail later on. For now, we'll just fill in the missing values with the overall mean for the column, like so:\n","\n","<left><img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1OmhXzMuPrGSmyyugGXpmrRlLznDHxOeT\"></left>\n","\n","In the diagram above, the mean of the first column is (1800 + 1600 + 2200 + 2300) / 4, or 1975, and the mean of the second column is (20 + 30 + 30 + 50) / 4, or 32.5. We replace the missing values with the means of their respective columns, which allows us to proceed with analyses that can't handle missing values (like correlations).\n","\n","We can fill in missing data in pandas using the [pandas.DataFrame.fillna()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html) method. This method will replace any missing values in a dataframe with the values we specify. We can compute the mean of every column using the [pandas.DataFrame.mean()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html) method. If we pass the results of the **df.mean()** method into the **df.fillna()** method, pandas will fill in the missing values in each column with the mean of that column.\n","\n","Here's an example of how we would accomplish this:\n","\n","```python\n","means = df.mean()\n","df = df.fillna(means)\n","```\n","\n","Note that if a column consists entirely of null or **NaN** values, pandas won't be able to fill in the missing values when we use the **df.fillna()** method along with the **df.mean()** method, because there won't be a mean.\n","\n","We should fill any **NaN** or null values that remain after the initial replacement with the value 0. We can do this by passing 0 into the **df.fillna()** method.\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Calculate the means of all of the columns in **combined** using the **pandas.DataFrame.mean()** method.\n","- Fill in any missing values in **combined** with the means of the respective columns using the **pandas.DataFrame.fillna()** method.\n","- Fill in any remaining missing values in **combined** with 0 using the **df.fillna()** method.\n","- Display the first few rows of **combined** to verify that the correct operations occurred."]},{"metadata":{"id":"XLJ8giWa8yGA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":627},"outputId":"ff7aecc6-30a6-48e6-d4d3-fb907701f545","executionInfo":{"status":"ok","timestamp":1544460690263,"user_tz":180,"elapsed":1014,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["combined = combined.fillna(combined.mean())\n","combined = combined.fillna(0)\n","\n","combined.head()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dbn</th>\n","      <th>school_name</th>\n","      <th>borough</th>\n","      <th>building_code</th>\n","      <th>phone_number</th>\n","      <th>fax_number</th>\n","      <th>grade_span_min</th>\n","      <th>grade_span_max</th>\n","      <th>expgrade_span_min</th>\n","      <th>expgrade_span_max</th>\n","      <th>...</th>\n","      <th>SchoolName</th>\n","      <th>AP Test Takers</th>\n","      <th>Total Exams Taken</th>\n","      <th>Number of Exams with scores 3 4 or 5</th>\n","      <th>SCHOOL NAME</th>\n","      <th>Num of SAT Test Takers</th>\n","      <th>SAT Critical Reading Avg. Score</th>\n","      <th>SAT Math Avg. Score</th>\n","      <th>SAT Writing Avg. Score</th>\n","      <th>sat_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17K548</td>\n","      <td>Brooklyn School for Music &amp; Theatre</td>\n","      <td>Brooklyn</td>\n","      <td>K440</td>\n","      <td>718-230-6250</td>\n","      <td>718-230-6262</td>\n","      <td>9.0</td>\n","      <td>12</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>Brooklyn School for Music &amp; Theatre</td>\n","      <td>37.000000</td>\n","      <td>41.00000</td>\n","      <td>9.000000</td>\n","      <td>BROOKLYN SCHOOL FOR MUSIC &amp; THEATRE</td>\n","      <td>48</td>\n","      <td>385.000000</td>\n","      <td>393.000000</td>\n","      <td>373.000000</td>\n","      <td>1151.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09X543</td>\n","      <td>High School for Violin and Dance</td>\n","      <td>Bronx</td>\n","      <td>X400</td>\n","      <td>718-842-0687</td>\n","      <td>718-589-9849</td>\n","      <td>9.0</td>\n","      <td>12</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>132.054455</td>\n","      <td>201.60396</td>\n","      <td>155.115942</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>413.122172</td>\n","      <td>431.013575</td>\n","      <td>408.733032</td>\n","      <td>1252.868778</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28Q680</td>\n","      <td>Queens Gateway to Health Sciences Secondary Sc...</td>\n","      <td>Queens</td>\n","      <td>Q695</td>\n","      <td>718-969-3155</td>\n","      <td>718-969-3552</td>\n","      <td>6.0</td>\n","      <td>12</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>GATEWAY TO HEALTH SCIENCES</td>\n","      <td>89.000000</td>\n","      <td>136.00000</td>\n","      <td>57.000000</td>\n","      <td>QUEENS GATEWAY TO HEALTH SCIENCES SECONDARY SC...</td>\n","      <td>99</td>\n","      <td>513.000000</td>\n","      <td>523.000000</td>\n","      <td>502.000000</td>\n","      <td>1538.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14K474</td>\n","      <td>PROGRESS High School for Professional Careers</td>\n","      <td>Brooklyn</td>\n","      <td>K450</td>\n","      <td>718-387-0228</td>\n","      <td>718-782-0911</td>\n","      <td>9.0</td>\n","      <td>12</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>PROGRESS HIGH SCHOOL</td>\n","      <td>50.000000</td>\n","      <td>66.00000</td>\n","      <td>155.115942</td>\n","      <td>PROGRESS HIGH SCHOOL FOR PROFESSIONAL CAREERS</td>\n","      <td>144</td>\n","      <td>364.000000</td>\n","      <td>379.000000</td>\n","      <td>371.000000</td>\n","      <td>1114.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>02M420</td>\n","      <td>High School for Health Professions and Human S...</td>\n","      <td>Manhattan</td>\n","      <td>M475</td>\n","      <td>212-780-9175</td>\n","      <td>212-979-7261</td>\n","      <td>9.0</td>\n","      <td>12</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>HEALTH PROF &amp; HUMAN SVCS</td>\n","      <td>204.000000</td>\n","      <td>248.00000</td>\n","      <td>75.000000</td>\n","      <td>HIGH SCHOOL FOR HEALTH PROFESSIONS AND HUMAN S...</td>\n","      <td>336</td>\n","      <td>429.000000</td>\n","      <td>449.000000</td>\n","      <td>428.000000</td>\n","      <td>1306.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 165 columns</p>\n","</div>"],"text/plain":["      dbn                                        school_name    borough  \\\n","0  17K548                Brooklyn School for Music & Theatre   Brooklyn   \n","1  09X543                   High School for Violin and Dance      Bronx   \n","2  28Q680  Queens Gateway to Health Sciences Secondary Sc...     Queens   \n","3  14K474      PROGRESS High School for Professional Careers   Brooklyn   \n","4  02M420  High School for Health Professions and Human S...  Manhattan   \n","\n","  building_code  phone_number    fax_number  grade_span_min  grade_span_max  \\\n","0          K440  718-230-6250  718-230-6262             9.0              12   \n","1          X400  718-842-0687  718-589-9849             9.0              12   \n","2          Q695  718-969-3155  718-969-3552             6.0              12   \n","3          K450  718-387-0228  718-782-0911             9.0              12   \n","4          M475  212-780-9175  212-979-7261             9.0              12   \n","\n","   expgrade_span_min  expgrade_span_max     ...       \\\n","0                0.0                0.0     ...        \n","1                0.0                0.0     ...        \n","2                0.0                0.0     ...        \n","3                0.0                0.0     ...        \n","4                0.0                0.0     ...        \n","\n","                            SchoolName AP Test Takers  Total Exams Taken  \\\n","0  Brooklyn School for Music & Theatre       37.000000          41.00000   \n","1                                    0      132.054455         201.60396   \n","2           GATEWAY TO HEALTH SCIENCES       89.000000         136.00000   \n","3                 PROGRESS HIGH SCHOOL       50.000000          66.00000   \n","4             HEALTH PROF & HUMAN SVCS      204.000000         248.00000   \n","\n","  Number of Exams with scores 3 4 or 5  \\\n","0                             9.000000   \n","1                           155.115942   \n","2                            57.000000   \n","3                           155.115942   \n","4                            75.000000   \n","\n","                                         SCHOOL NAME  Num of SAT Test Takers  \\\n","0                BROOKLYN SCHOOL FOR MUSIC & THEATRE                      48   \n","1                                                  0                       0   \n","2  QUEENS GATEWAY TO HEALTH SCIENCES SECONDARY SC...                      99   \n","3      PROGRESS HIGH SCHOOL FOR PROFESSIONAL CAREERS                     144   \n","4  HIGH SCHOOL FOR HEALTH PROFESSIONS AND HUMAN S...                     336   \n","\n","  SAT Critical Reading Avg. Score  SAT Math Avg. Score SAT Writing Avg. Score  \\\n","0                      385.000000           393.000000             373.000000   \n","1                      413.122172           431.013575             408.733032   \n","2                      513.000000           523.000000             502.000000   \n","3                      364.000000           379.000000             371.000000   \n","4                      429.000000           449.000000             428.000000   \n","\n","     sat_score  \n","0  1151.000000  \n","1  1252.868778  \n","2  1538.000000  \n","3  1114.000000  \n","4  1306.000000  \n","\n","[5 rows x 165 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"metadata":{"id":"TkFLrp0r8yGG","colab_type":"text"},"cell_type":"markdown","source":["## 1.15 Adding a School District Column for Mapping"]},{"metadata":{"id":"Bhwo7emM8yGG","colab_type":"text"},"cell_type":"markdown","source":["We've finished cleaning and combining our data! We now have a clean data set on which we can base our analysis. Mapping the statistics out on a school district level might be an interesting way to analyze them. Adding a column to the data set that specifies the school district will help us accomplish this.\n","\n","The school district is just the first two characters of the **DBN**. We can apply a function over the **DBN** column of **combined** that pulls out the first two letters.\n","\n","For example, we can use indexing to extract the first few characters of a string, like this:\n","\n","```python\n","name = \"Sinbad\"\n","print(name[0:2])\n","```\n","\n","**Exercise**\n","\n","<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n","\n","- Write a function that extracts the first two characters of a string and returns them.\n","- Apply the function to the **DBN** column of **combined**, and assign the result to the **school_dist** column of **combined**.\n","- Display the first few items in the **school_dist** column of **combined** to verify the results.\n"]},{"metadata":{"id":"gIk75azA8yGG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"8110b0e2-168a-4493-dc4b-fc8ae88f93b4","executionInfo":{"status":"ok","timestamp":1544460741007,"user_tz":180,"elapsed":844,"user":{"displayName":"Michel Jean Katsilis","photoUrl":"","userId":"00176276256913421264"}}},"cell_type":"code","source":["def get_first_two(input_str):\n","  return input_str[0:2]\n","\n","combined['school_dist'] = combined['DBN'].apply(get_first_two)\n","\n","combined['school_dist'].head()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    17\n","1    09\n","2    28\n","3    14\n","4    02\n","Name: school_dist, dtype: object"]},"metadata":{"tags":[]},"execution_count":39}]},{"metadata":{"id":"q8407VxT8yGK","colab_type":"text"},"cell_type":"markdown","source":["## 1.16 Next Steps"]},{"metadata":{"id":"0YOOKVLg8yGK","colab_type":"text"},"cell_type":"markdown","source":["We now have a clean data set we can analyze! We've done a lot in this mission. We've gone from having several messy sources to one clean, combined, data set that's ready for analysis.\n","\n","Along the way, we've learned about:\n","\n","- How to handle missing values\n","- Different types of merges\n","- How to condense data sets\n","- How to compute averages across dataframes\n","\n","Data scientists rarely start out with tidy data sets, which makes cleaning and combining them one of the most critical skills any data professional can learn.\n"]}]}